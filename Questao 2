from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Inicializar a sessão Spark
spark = SparkSession.builder.appName("NewYorkTripsAnalysis").getOrCreate()

# Carregar o esquema dos dados do arquivo JSON fornecido
schema_json = spark.read.json("bq_newyork_trips_schema.json")

# Carregar os dados em um DataFrame usando o arquivo CSV correto
trips_df = spark.read.csv("newyork_citibikes_trips.csv", header=True, schema=schema_json.schema)

# Remover viagens sem duração
trips_df = trips_df.filter(col("tripduration").isNotNull() & (col("tripduration") > 0))

# Calcular a duração média das viagens
average_duration = trips_df.agg({"tripduration": "avg"}).collect()[0][0]

# Encontrar as 10 viagens mais rápidas
fastest_trips = trips_df.orderBy(col("tripduration").asc()).limit(10)

# Mostrar os resultados
print(f"A duração média das viagens é: {average_duration} segundos")
print("As 10 viagens mais rápidas são:")
fastest_trips.show()

# Parar a sessão Spark
spark.stop()
