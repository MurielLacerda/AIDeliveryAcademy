from pyspark.sql import SparkSession
from pyspark.sql.functions import count

# Inicializar a sessão Spark
spark = SparkSession.builder.appName("BikeTripsAnalysis").getOrCreate()

# Carregar os dados em um DataFrame
trips_df = spark.read.csv("newyork_citibikes_trips.csv", header=True, inferSchema=True)

# Calcular o total de viagens por bicicleta
total_trips_per_bike = trips_df.groupBy("bikeid").agg(count("tripduration").alias("total_trips"))

# Encontrar as 10 bicicletas mais utilizadas
most_used_bikes = total_trips_per_bike.orderBy("total_trips", ascending=False).limit(10)

# Mostrar os resultados
most_used_bikes.show()

# Parar a sessão Spark
spark.stop()
